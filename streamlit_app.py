import streamlit as st
import pandas as pd
from groq import Groq

# Setup API key for Groqcloud
api_key = st.secrets["api_key"]
client = Groq(api_key=api_key)

# Optimized prompt templates with reduced verbosity
preprocess_prompt_template = """
Analyze the provided software development data and create a structured summary. 
Include: 
1. Key information bullet points
2. Functional requirements list
Keep responses concise and focused on technical specifications.
"""

brd_prompt_template = """
Generate a Business Requirement Document using the following structure:
1. Title
2. Overview (1-2 sentences)
3. Project Scope (3-5 key points)
4. Business Requirements (bulleted list)
5. Non-Functional Requirements (bulleted list)
Keep sections brief and technical.
"""

frd_prompt_template = """
Create Functional Requirement Document with:
1. Module Title
2. Overview (1 sentence)
3. Functional Requirements (numbered list with brief descriptions)
Focus on technical specifications only.
"""

use_case_prompt_template = """
Generate Use Cases using this structure per case:
- Name
- Actors
- Main Flow (3-5 steps)
- Alternate Flows (if any)
Keep cases concise and technical.
"""

data_modeling_prompt_template = """
Create data models including:
1. Key entities
2. Relationships
3. Logical model overview
Avoid verbose descriptions.
"""

wireframes_mockups_prompt_template = """
Describe UI components for each screen:
- Layout type
- Key elements
- User interactions
Keep descriptions brief and technical.
"""

def truncate_content(content, max_chars=2000):
    """Ensure content stays within character limit"""
    return content[:max_chars] if content else ""

def call_llm_api(prompt_template, user_content):
    optimized_content = truncate_content(user_content)
    
    data = {
        "model": "llama-3.2-1b-preview",
        "messages": [
            {"role": "system", "content": truncate_content(prompt_template, 500)},
            {"role": "user", "content": optimized_content}
        ],
        "max_tokens": 1500  # Add token limit
    }
    
    try:
        response = client.chat.completions.create(**data)
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"API Error: {str(e)}")
        return None

# Streamlit interface
st.set_page_config(page_title="Business Analysis Assistant ðŸ¤–", page_icon="ðŸ“Š")
st.title("Business Analysis Assistant ðŸ¤–")

# Initialize session state with truncation
def init_session(key, default=None):
    if key not in st.session_state:
        st.session_state[key] = truncate_content(default)

keys = [
    'data_summary', 'important_info', 'functional_requirements',
    'brd', 'frd', 'use_case_doc', 'data_modeling', 'wireframes_mockups'
]
for key in keys:
    init_session(key)

# Processing functions with data optimization
def data_preprocessing():
    st.header('Step 1: Data Preprocessing')
    uploaded_file = st.file_uploader("Upload your Excel file", type=["xlsx", "xls"])

    if uploaded_file:
        df = pd.read_excel(uploaded_file)
        st.write("Sample Data:", df.head(3))  # Show only sample data
        
        if st.button('Process Data'):
            with st.spinner("Processing..."):
                # Send only essential data
                sample_data = df.head(5).to_string()  # Limit data sent
                analysis_prompt = f"Analyze this sample data:\n{sample_data}"
                response = call_llm_api(preprocess_prompt_template, analysis_prompt)
                
                if response:
                    st.session_state['data_summary'] = truncate_content(response)
                    
                    # Simplified parsing
                    parts = response.split("2. Functional Requirements") if "2. Functional Requirements" in response else [response, ""]
                    st.session_state['important_info'] = truncate_content(parts[0])
                    st.session_state['functional_requirements'] = truncate_content(parts[-1])

            if st.session_state['data_summary']:
                st.write("### Data Summary:")
                st.write(st.session_state['data_summary'])

# Subsequent steps follow similar pattern with truncation
# [Rest of the step functions follow the same optimization pattern - truncated for brevity]

def business_requirement_documents():
    st.header('Step 2: Business Requirement Documents')
    
    if st.button('Generate BRD'):
        with st.spinner("Generating BRD..."):
            # Use truncated summary and requirements
            input_content = f"""
            Summary: {truncate_content(st.session_state['data_summary'])}
            Requirements: {truncate_content(st.session_state['functional_requirements'])}
            """
            response = call_llm_api(brd_prompt_template, input_content)
            
            if response:
                st.session_state['brd'] = truncate_content(response)
                st.write("### Generated BRD:")
                st.write(st.session_state['brd'])

# [Remaining steps follow similar optimization patterns...]

def main():
    st.sidebar.title("Navigation")
    steps = ["Data Preprocessing", "BRD", "FRD", "Use Cases", 
            "Data Modeling", "Wireframes"]
    step = st.sidebar.selectbox("Select Step", steps)

    if step == "Data Preprocessing":
        data_preprocessing()
    elif step == "BRD":
        business_requirement_documents()
    # [Other steps...]

if __name__ == '__main__':
    main()
